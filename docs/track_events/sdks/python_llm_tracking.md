Here we'll cover how to automatically track events from LLM models in python. Events such as prompts, generations and tool calls can be captured with just a few lines of code.

## Foundation models

=== "Azure OpenAI"

    ``` py
    # Coming soon
    ```

=== "Aleph Alpha"

    ``` py
    # Coming soon
    ```

=== "Anthropic"

    ``` py
    # Coming soon
    ```

=== "Amazon Bedrock"

    ``` py
    # Coming soon
    ```

=== "Amazon Sagemaker"

    ``` py
    # Coming soon
    ```

=== "Cohere"

    ``` py
    # Coming soon
    ```

=== "IBM Watson"

    ``` py
    # Coming soon
    ```

=== "Google Gemini"

    ``` py
    # Coming soon
    ```

=== "Google VertexAI"

    ``` py
    # Coming soon
    ```

=== "Mistral AI"

    ``` py
    # Coming soon
    ``` 

=== "Ollama"

    ``` py
    # Coming soon
    ```

=== "OpenAI"

    ``` py
    # Coming soon
    ```

=== "Replicate"

    ``` py
    # Coming soon
    ```

=== "together.ai"

    ``` py
    # Coming soon
    ```

=== "HuggingFace Transformers"

    ``` py
    # Coming soon
    ```

## Frameworks

=== "Burr"

    ``` py
    # Coming soon
    ```

=== "Haystack by deepset"

    ``` py
    # Coming soon
    ```

=== "Langchain"

    ``` py
    # Coming soon
    ```

=== "LlamaIndex"

    ``` py
    # Coming soon
    ```
